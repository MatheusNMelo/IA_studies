{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9aabafca-8129-4943-b865-d5e897637253",
   "metadata": {},
   "source": [
    "![image](car.jpeg)\n",
    "\n",
    "**Car-ing is sharing**, an auto dealership company for car sales and rental, is taking their services to the next level thanks to **Large Language Models (LLMs)**.\n",
    "\n",
    "As their newly recruited AI and NLP developer, you've been asked to prototype a chatbot app with multiple functionalities that not only assist customers but also provide support to human agents in the company.\n",
    "\n",
    "The solution should receive textual prompts and use a variety of pre-trained Hugging Face LLMs to respond to a series of tasks, e.g. classifying the sentiment in a car’s text review, answering a customer question, summarizing or translating text, etc.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76e43a5-66eb-46b8-86cb-7921e9823e77",
   "metadata": {},
   "source": [
    "The CTO at \"Car-ing is sharing\", a car sales and rental company, hired you to help prototype a chatbot app that addresses diverse inquiries using LLMs. She proposed you piloting the following tasks:\n",
    "\n",
    "Tasks:\n",
    "\n",
    "1 -\n",
    "Use a pre-trained LLM to classify the sentiment of the five car reviews in the car_reviews.csv dataset, and evaluate the classification accuracy and F1 score of predictions.\n",
    "Store the model outputs in predicted_labels, then extract the labels and map them onto a list of {0,1} integer binary labels called predictions.\n",
    "Store the calculated metrics in accuracy_result and f1_result.\n",
    "\n",
    "2 -\n",
    "The company is recently attracting customers from Spain. Extract and pass the first two sentences of the first review in the dataset to an English-to-Spanish translation LLM. Calculate the BLEU score to assess translation quality, using the content in reference_translations.txt as references.\n",
    "Store the translated text generated by the LLM in translated_review.\n",
    "Store the BLEU score metric result in bleu_score.\n",
    "\n",
    "3 - \n",
    "The 2nd review in the dataset emphasizes brand aspects. Load an extractive QA LLM such as \"deepset/minilm-uncased-squad2\" to formulate the question \"What did he like about the brand?\" and obtain an answer.\n",
    "Use question and context for the two variables containing the LLM inputs: question and context.\n",
    "Store the actual text answer in answer.\n",
    "\n",
    "4 -\n",
    "Summarize the last review in the dataset, into approximately 50-55 tokens long. Store it in the variable summarized_text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a374335d",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5325a4c0-ceb3-4b66-acd2-5eadcefe3a63",
   "metadata": {
    "collapsed": true,
    "executionCancelledAt": null,
    "executionTime": 13048,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": false
    },
    "lastExecutedAt": 1739977370623,
    "lastExecutedByKernel": "15406b38-91f6-4175-ab8a-c77435acaf89",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "!pip install transformers\n!pip install evaluate==0.4.0\n!pip install datasets==2.10.0\n!pip install sentencepiece==0.1.97\n\nfrom transformers import logging\nlogging.set_verbosity(logging.WARNING)\nimport torch\nimport evaluate\nimport pandas as pd\nfrom transformers import DistilBertTokenizer, DistilBertForSequenceClassification, pipeline\nfrom transformers import AutoTokenizer\nfrom transformers import AutoModelForQuestionAnswering",
    "outputsMetadata": {
     "0": {
      "height": 616,
      "type": "stream"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.49.0-py3-none-any.whl.metadata (44 kB)\n",
      "Collecting filelock (from transformers)\n",
      "  Downloading filelock-3.17.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.26.0 (from transformers)\n",
      "  Downloading huggingface_hub-0.29.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting numpy>=1.17 (from transformers)\n",
      "  Downloading numpy-2.2.3-cp313-cp313-win_amd64.whl.metadata (60 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\mathe\\appdata\\roaming\\python\\python313\\site-packages (from transformers) (24.2)\n",
      "Collecting pyyaml>=5.1 (from transformers)\n",
      "  Downloading PyYAML-6.0.2-cp313-cp313-win_amd64.whl.metadata (2.1 kB)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Downloading regex-2024.11.6-cp313-cp313-win_amd64.whl.metadata (41 kB)\n",
      "Collecting requests (from transformers)\n",
      "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers)\n",
      "  Downloading tokenizers-0.21.0-cp39-abi3-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers)\n",
      "  Downloading safetensors-0.5.2-cp38-abi3-win_amd64.whl.metadata (3.9 kB)\n",
      "Collecting tqdm>=4.27 (from transformers)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.26.0->transformers)\n",
      "  Downloading fsspec-2025.2.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting typing-extensions>=3.7.4.3 (from huggingface-hub<1.0,>=0.26.0->transformers)\n",
      "  Using cached typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\mathe\\appdata\\roaming\\python\\python313\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Collecting charset-normalizer<4,>=2 (from requests->transformers)\n",
      "  Downloading charset_normalizer-3.4.1-cp313-cp313-win_amd64.whl.metadata (36 kB)\n",
      "Collecting idna<4,>=2.5 (from requests->transformers)\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests->transformers)\n",
      "  Downloading urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests->transformers)\n",
      "  Downloading certifi-2025.1.31-py3-none-any.whl.metadata (2.5 kB)\n",
      "Downloading transformers-4.49.0-py3-none-any.whl (10.0 MB)\n",
      "   ---------------------------------------- 0.0/10.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 10.0/10.0 MB 58.2 MB/s eta 0:00:00\n",
      "Downloading huggingface_hub-0.29.0-py3-none-any.whl (468 kB)\n",
      "Downloading numpy-2.2.3-cp313-cp313-win_amd64.whl (12.6 MB)\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 12.6/12.6 MB 65.1 MB/s eta 0:00:00\n",
      "Downloading PyYAML-6.0.2-cp313-cp313-win_amd64.whl (156 kB)\n",
      "Downloading regex-2024.11.6-cp313-cp313-win_amd64.whl (273 kB)\n",
      "Downloading safetensors-0.5.2-cp38-abi3-win_amd64.whl (303 kB)\n",
      "Downloading tokenizers-0.21.0-cp39-abi3-win_amd64.whl (2.4 MB)\n",
      "   ---------------------------------------- 0.0/2.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.4/2.4 MB 72.9 MB/s eta 0:00:00\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Downloading filelock-3.17.0-py3-none-any.whl (16 kB)\n",
      "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Downloading certifi-2025.1.31-py3-none-any.whl (166 kB)\n",
      "Downloading charset_normalizer-3.4.1-cp313-cp313-win_amd64.whl (102 kB)\n",
      "Downloading fsspec-2025.2.0-py3-none-any.whl (184 kB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Using cached typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Downloading urllib3-2.3.0-py3-none-any.whl (128 kB)\n",
      "Installing collected packages: urllib3, typing-extensions, tqdm, safetensors, regex, pyyaml, numpy, idna, fsspec, filelock, charset-normalizer, certifi, requests, huggingface-hub, tokenizers, transformers\n",
      "Successfully installed certifi-2025.1.31 charset-normalizer-3.4.1 filelock-3.17.0 fsspec-2025.2.0 huggingface-hub-0.29.0 idna-3.10 numpy-2.2.3 pyyaml-6.0.2 regex-2024.11.6 requests-2.32.3 safetensors-0.5.2 tokenizers-0.21.0 tqdm-4.67.1 transformers-4.49.0 typing-extensions-4.12.2 urllib3-2.3.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting evaluate==0.4.0\n",
      "  Downloading evaluate-0.4.0-py3-none-any.whl.metadata (9.4 kB)\n",
      "Collecting datasets>=2.0.0 (from evaluate==0.4.0)\n",
      "  Downloading datasets-3.3.1-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\mathe\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from evaluate==0.4.0) (2.2.3)\n",
      "Collecting dill (from evaluate==0.4.0)\n",
      "  Downloading dill-0.3.9-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting pandas (from evaluate==0.4.0)\n",
      "  Using cached pandas-2.2.3-cp313-cp313-win_amd64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\mathe\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from evaluate==0.4.0) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in c:\\users\\mathe\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from evaluate==0.4.0) (4.67.1)\n",
      "Collecting xxhash (from evaluate==0.4.0)\n",
      "  Downloading xxhash-3.5.0-cp313-cp313-win_amd64.whl.metadata (13 kB)\n",
      "Collecting multiprocess (from evaluate==0.4.0)\n",
      "  Downloading multiprocess-0.70.17-py313-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in c:\\users\\mathe\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from fsspec[http]>=2021.05.0->evaluate==0.4.0) (2025.2.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in c:\\users\\mathe\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from evaluate==0.4.0) (0.29.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\mathe\\appdata\\roaming\\python\\python313\\site-packages (from evaluate==0.4.0) (24.2)\n",
      "Collecting responses<0.19 (from evaluate==0.4.0)\n",
      "  Downloading responses-0.18.0-py3-none-any.whl.metadata (29 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\mathe\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from datasets>=2.0.0->evaluate==0.4.0) (3.17.0)\n",
      "Collecting pyarrow>=15.0.0 (from datasets>=2.0.0->evaluate==0.4.0)\n",
      "  Downloading pyarrow-19.0.1-cp313-cp313-win_amd64.whl.metadata (3.4 kB)\n",
      "Collecting dill (from evaluate==0.4.0)\n",
      "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting multiprocess (from evaluate==0.4.0)\n",
      "  Downloading multiprocess-0.70.16-py312-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec>=2021.05.0 (from fsspec[http]>=2021.05.0->evaluate==0.4.0)\n",
      "  Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting aiohttp (from datasets>=2.0.0->evaluate==0.4.0)\n",
      "  Downloading aiohttp-3.11.12-cp313-cp313-win_amd64.whl.metadata (8.0 kB)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\mathe\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from datasets>=2.0.0->evaluate==0.4.0) (6.0.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\mathe\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from huggingface-hub>=0.7.0->evaluate==0.4.0) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\mathe\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests>=2.19.0->evaluate==0.4.0) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\mathe\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests>=2.19.0->evaluate==0.4.0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\mathe\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests>=2.19.0->evaluate==0.4.0) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mathe\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests>=2.19.0->evaluate==0.4.0) (2025.1.31)\n",
      "Requirement already satisfied: colorama in c:\\users\\mathe\\appdata\\roaming\\python\\python313\\site-packages (from tqdm>=4.62.1->evaluate==0.4.0) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\mathe\\appdata\\roaming\\python\\python313\\site-packages (from pandas->evaluate==0.4.0) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas->evaluate==0.4.0)\n",
      "  Downloading pytz-2025.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas->evaluate==0.4.0)\n",
      "  Downloading tzdata-2025.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp->datasets>=2.0.0->evaluate==0.4.0)\n",
      "  Downloading aiohappyeyeballs-2.4.6-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->datasets>=2.0.0->evaluate==0.4.0)\n",
      "  Downloading aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp->datasets>=2.0.0->evaluate==0.4.0)\n",
      "  Downloading attrs-25.1.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->datasets>=2.0.0->evaluate==0.4.0)\n",
      "  Using cached frozenlist-1.5.0-cp313-cp313-win_amd64.whl.metadata (14 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets>=2.0.0->evaluate==0.4.0)\n",
      "  Using cached multidict-6.1.0-cp313-cp313-win_amd64.whl.metadata (5.1 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp->datasets>=2.0.0->evaluate==0.4.0)\n",
      "  Downloading propcache-0.2.1-cp313-cp313-win_amd64.whl.metadata (9.5 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp->datasets>=2.0.0->evaluate==0.4.0)\n",
      "  Downloading yarl-1.18.3-cp313-cp313-win_amd64.whl.metadata (71 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\mathe\\appdata\\roaming\\python\\python313\\site-packages (from python-dateutil>=2.8.2->pandas->evaluate==0.4.0) (1.17.0)\n",
      "Downloading evaluate-0.4.0-py3-none-any.whl (81 kB)\n",
      "Downloading datasets-3.3.1-py3-none-any.whl (484 kB)\n",
      "Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Downloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n",
      "Downloading multiprocess-0.70.16-py312-none-any.whl (146 kB)\n",
      "Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
      "Using cached pandas-2.2.3-cp313-cp313-win_amd64.whl (11.5 MB)\n",
      "Downloading xxhash-3.5.0-cp313-cp313-win_amd64.whl (30 kB)\n",
      "Downloading aiohttp-3.11.12-cp313-cp313-win_amd64.whl (436 kB)\n",
      "Downloading pyarrow-19.0.1-cp313-cp313-win_amd64.whl (25.2 MB)\n",
      "   ---------------------------------------- 0.0/25.2 MB ? eta -:--:--\n",
      "   --------------------------- ------------ 17.3/25.2 MB 83.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 25.2/25.2 MB 61.4 MB/s eta 0:00:00\n",
      "Downloading pytz-2025.1-py2.py3-none-any.whl (507 kB)\n",
      "Downloading tzdata-2025.1-py2.py3-none-any.whl (346 kB)\n",
      "Downloading aiohappyeyeballs-2.4.6-py3-none-any.whl (14 kB)\n",
      "Downloading aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading attrs-25.1.0-py3-none-any.whl (63 kB)\n",
      "Using cached frozenlist-1.5.0-cp313-cp313-win_amd64.whl (51 kB)\n",
      "Using cached multidict-6.1.0-cp313-cp313-win_amd64.whl (28 kB)\n",
      "Downloading propcache-0.2.1-cp313-cp313-win_amd64.whl (43 kB)\n",
      "Downloading yarl-1.18.3-cp313-cp313-win_amd64.whl (315 kB)\n",
      "Installing collected packages: pytz, xxhash, tzdata, pyarrow, propcache, multidict, fsspec, frozenlist, dill, attrs, aiohappyeyeballs, yarl, responses, pandas, multiprocess, aiosignal, aiohttp, datasets, evaluate\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2025.2.0\n",
      "    Uninstalling fsspec-2025.2.0:\n",
      "      Successfully uninstalled fsspec-2025.2.0\n",
      "Successfully installed aiohappyeyeballs-2.4.6 aiohttp-3.11.12 aiosignal-1.3.2 attrs-25.1.0 datasets-3.3.1 dill-0.3.8 evaluate-0.4.0 frozenlist-1.5.0 fsspec-2024.12.0 multidict-6.1.0 multiprocess-0.70.16 pandas-2.2.3 propcache-0.2.1 pyarrow-19.0.1 pytz-2025.1 responses-0.18.0 tzdata-2025.1 xxhash-3.5.0 yarl-1.18.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.Collecting datasets==2.10.0\n",
      "  Downloading datasets-2.10.0-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\mathe\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from datasets==2.10.0) (2.2.3)\n",
      "Requirement already satisfied: pyarrow>=6.0.0 in c:\\users\\mathe\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from datasets==2.10.0) (19.0.1)\n",
      "Collecting dill<0.3.7,>=0.3.0 (from datasets==2.10.0)\n",
      "  Downloading dill-0.3.6-py3-none-any.whl.metadata (9.8 kB)\n",
      "Requirement already satisfied: pandas in c:\\users\\mathe\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from datasets==2.10.0) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\mathe\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from datasets==2.10.0) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in c:\\users\\mathe\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from datasets==2.10.0) (4.67.1)\n",
      "Requirement already satisfied: xxhash in c:\\users\\mathe\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from datasets==2.10.0) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\mathe\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from datasets==2.10.0) (0.70.16)\n",
      "Requirement already satisfied: fsspec>=2021.11.1 in c:\\users\\mathe\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from fsspec[http]>=2021.11.1->datasets==2.10.0) (2024.12.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\mathe\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from datasets==2.10.0) (3.11.12)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in c:\\users\\mathe\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from datasets==2.10.0) (0.29.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\mathe\\appdata\\roaming\\python\\python313\\site-packages (from datasets==2.10.0) (24.2)\n",
      "Requirement already satisfied: responses<0.19 in c:\\users\\mathe\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from datasets==2.10.0) (0.18.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\mathe\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from datasets==2.10.0) (6.0.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\mathe\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp->datasets==2.10.0) (2.4.6)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\mathe\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp->datasets==2.10.0) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\mathe\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp->datasets==2.10.0) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\mathe\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp->datasets==2.10.0) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\mathe\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp->datasets==2.10.0) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\mathe\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp->datasets==2.10.0) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\mathe\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp->datasets==2.10.0) (1.18.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\mathe\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets==2.10.0) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\mathe\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets==2.10.0) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\mathe\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests>=2.19.0->datasets==2.10.0) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\mathe\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests>=2.19.0->datasets==2.10.0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\mathe\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests>=2.19.0->datasets==2.10.0) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mathe\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests>=2.19.0->datasets==2.10.0) (2025.1.31)\n",
      "Requirement already satisfied: colorama in c:\\users\\mathe\\appdata\\roaming\\python\\python313\\site-packages (from tqdm>=4.62.1->datasets==2.10.0) (0.4.6)\n",
      "INFO: pip is looking at multiple versions of multiprocess to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting multiprocess (from datasets==2.10.0)\n",
      "  Using cached multiprocess-0.70.17-py313-none-any.whl.metadata (7.2 kB)\n",
      "  Downloading multiprocess-0.70.15-py311-none-any.whl.metadata (7.2 kB)\n",
      "  Downloading multiprocess-0.70.14-py310-none-any.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\mathe\\appdata\\roaming\\python\\python313\\site-packages (from pandas->datasets==2.10.0) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\mathe\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas->datasets==2.10.0) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\mathe\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas->datasets==2.10.0) (2025.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\mathe\\appdata\\roaming\\python\\python313\\site-packages (from python-dateutil>=2.8.2->pandas->datasets==2.10.0) (1.17.0)\n",
      "Downloading datasets-2.10.0-py3-none-any.whl (469 kB)\n",
      "Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
      "Downloading multiprocess-0.70.14-py310-none-any.whl (134 kB)\n",
      "Installing collected packages: dill, multiprocess, datasets\n",
      "  Attempting uninstall: dill\n",
      "    Found existing installation: dill 0.3.8\n",
      "    Uninstalling dill-0.3.8:\n",
      "      Successfully uninstalled dill-0.3.8\n",
      "  Attempting uninstall: multiprocess\n",
      "    Found existing installation: multiprocess 0.70.16\n",
      "    Uninstalling multiprocess-0.70.16:\n",
      "      Successfully uninstalled multiprocess-0.70.16\n",
      "  Attempting uninstall: datasets\n",
      "    Found existing installation: datasets 3.3.1\n",
      "    Uninstalling datasets-3.3.1:\n",
      "      Successfully uninstalled datasets-3.3.1\n",
      "Successfully installed datasets-2.10.0 dill-0.3.6 multiprocess-0.70.14\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentencepiece==0.1.97\n",
      "  Downloading sentencepiece-0.1.97.tar.gz (524 kB)\n",
      "     ---------------------------------------- 0.0/524.7 kB ? eta -:--:--\n",
      "     ------------------------------------- 524.7/524.7 kB 15.7 MB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Building wheels for collected packages: sentencepiece\n",
      "  Building wheel for sentencepiece (pyproject.toml): started\n",
      "  Building wheel for sentencepiece (pyproject.toml): finished with status 'error'\n",
      "Failed to build sentencepiece\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × Building wheel for sentencepiece (pyproject.toml) did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [13 lines of output]\n",
      "      C:\\Users\\mathe\\AppData\\Local\\Temp\\pip-build-env-0b3xzixc\\overlay\\Lib\\site-packages\\setuptools\\_distutils\\dist.py:270: UserWarning: Unknown distribution option: 'test_suite'\n",
      "        warnings.warn(msg)\n",
      "      running bdist_wheel\n",
      "      running build\n",
      "      running build_py\n",
      "      creating build\\lib.win-amd64-cpython-313\\sentencepiece\n",
      "      copying src\\sentencepiece/__init__.py -> build\\lib.win-amd64-cpython-313\\sentencepiece\n",
      "      copying src\\sentencepiece/_version.py -> build\\lib.win-amd64-cpython-313\\sentencepiece\n",
      "      copying src\\sentencepiece/sentencepiece_model_pb2.py -> build\\lib.win-amd64-cpython-313\\sentencepiece\n",
      "      copying src\\sentencepiece/sentencepiece_pb2.py -> build\\lib.win-amd64-cpython-313\\sentencepiece\n",
      "      running build_ext\n",
      "      building 'sentencepiece._sentencepiece' extension\n",
      "      error: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for sentencepiece\n",
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "ERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (sentencepiece)\n"
     ]
    }
   ],
   "source": [
    "%pip install transformers\n",
    "%pip install evaluate==0.4.0\n",
    "%pip install datasets==2.10.0\n",
    "%pip install sentencepiece==0.1.97\n",
    "%pip install torch\n",
    "%pip install pandas\n",
    "\n",
    "from transformers import logging\n",
    "logging.set_verbosity(logging.WARNING)\n",
    "import torch\n",
    "import evaluate\n",
    "import pandas as pd\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification, pipeline\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForQuestionAnswering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87194f9-6d40-4eec-b04f-f967e19aa69e",
   "metadata": {},
   "source": [
    "## TASK 1 - Sentiment Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "26f0b025-f29d-41c8-b4a7-a9dd6ddfa4c1",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 1460,
    "lastExecutedAt": 1739977372085,
    "lastExecutedByKernel": "15406b38-91f6-4175-ab8a-c77435acaf89",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "file_path = \"data/car_reviews.csv\"\ndf = pd.read_csv(file_path, delimiter=\";\")\n\nreviews = df['Review'].tolist()\nreal_labels = df['Class'].tolist()\n\nclassifier = pipeline('sentiment-analysis', model='distilbert-base-uncased-finetuned-sst-2-english')\n\npredicted_labels = classifier(reviews)\nfor review, prediction, label in zip(reviews, predicted_labels, real_labels):\n    print(f\"Review: {review}\\nActual Sentiment: {label}\\nPredicted Sentiment: {prediction['label']} (Confidence: {prediction['score']:.4f})\\n\")\n",
    "outputsMetadata": {
     "0": {
      "height": 616,
      "type": "stream"
     },
     "4": {
      "height": 80,
      "type": "stream"
     },
     "5": {
      "height": 616,
      "type": "stream"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: I am very satisfied with my 2014 Nissan NV SL. I use this van for my business deliveries and personal use. Camping, road trips, etc. We dont have any children so I store most of the seats in my warehouse. I wanted the passenger van for the rear air conditioning. We drove our van from Florida to California for a Cross Country trip in 2014. We averaged about 18 mpg. We drove thru a lot of rain and It was a very comfortable and stable vehicle. The V8 Nissan Titan engine is a 500k mile engine. It has been tested many times by delivery and trucking companies. This is why Nissan gives you a 5 year or 100k mile bumper to bumper warranty. Many people are scared about driving this van because of its size. But with front and rear sonar sensors, large mirrors and the back up camera. It is easy to drive. The front and rear sensors also monitor the front and rear sides of the bumpers making it easier to park close to objects. Our Nissan NV is a Tow Monster. It pulls our 5000 pound travel trailer like its not even there. I have plenty of power to pass a vehicle if needed. The 5.6 liter engine produces 317 hp. I have owned Chevy and Ford vans and there were not very comfortable and had little cockpit room. The Nissan NV is the only vehicle made that has the engine forward like a pick up truck giving the driver plenty of room and comfort in the cockpit area. I dont have any negatives to say about my NV. This is a wide vehicle. The only modification I would like to see from Nissan is for them to add amber side mirror marker lights.BTW. I now own a 2016 Nissan NVP SL. Love it.\n",
      "Actual Sentiment: POSITIVE\n",
      "Predicted Sentiment: POSITIVE (Confidence: 0.9294)\n",
      "\n",
      "Review: The car is fine. It's a bit loud and not very powerful. On one hand, compared to its peers, the interior is well-built. The transmission failed a few years ago, and the dealer replaced it under warranty with no issues. Now, about 60k miles later, the transmission is failing again. It sounds like a truck, and the issues are well-documented. The dealer tells me it is normal, refusing to do anything to resolve the issue. After owning the car for 4 years, there are many other vehicles I would purchase over this one. Initially, I really liked what the brand is about: ride quality, reliability, etc. But I will not purchase another one. Despite these concerns, I must say, the level of comfort in the car has always been satisfactory, but not worth the rest of issues found.\n",
      "Actual Sentiment: NEGATIVE\n",
      "Predicted Sentiment: POSITIVE (Confidence: 0.8654)\n",
      "\n",
      "Review: My first foreign car. Love it, I would buy another.\n",
      "Actual Sentiment: POSITIVE\n",
      "Predicted Sentiment: POSITIVE (Confidence: 0.9995)\n",
      "\n",
      "Review: I've come across numerous reviews praising the Rogue, and I genuinely feel like I might be missing something. It's only been a week since I got the car, and I am genuinely disappointed. I truly wish I could return it. My main concern revolves around what I see as a significant design flaw (which I believe also exists in the Murano, though that wasn't much better and considerably pricier). The rear windshield is just too small. The headrests in the back seat obstruct the sides of the rearview window. This \"Crossover\" feels more like a cheaply made compact car. My other vehicle is a Sonata, and it provides a significantly quieter and smoother ride. I did not anticipate this car to ride so roughly; my 2006 Pathfinder had a smoother ride! I would rate this car a 5 all around.\n",
      "Actual Sentiment: NEGATIVE\n",
      "Predicted Sentiment: NEGATIVE (Confidence: 0.9935)\n",
      "\n",
      "Review: I've been dreaming of owning an SUV for quite a while, but I've been driving cars that were already paid for during an extended period. I ultimately made the decision to transition to a brand-new car, which, of course, involved taking on new payments. However, given that I don't drive extensively, I was inclined to avoid a substantial financial commitment. The Nissan Rogue provides me with the desired SUV experience without burdening me with an exorbitant payment; the financial arrangement is quite reasonable. Handling and styling are great; I have hauled 12 bags of mulch in the back with the seats down and could have held more. I am VERY satisfied overall. I find myself needing to exercise extra caution when making lane changes, particularly owing to the blind spots resulting from the small side windows situated towards the rear of the vehicle. To address this concern, I am actively engaged in making adjustments to my mirrors and consciously reducing the frequency of lane changes. The engine delivers strong performance, and the ride is really smooth.\n",
      "Actual Sentiment: POSITIVE\n",
      "Predicted Sentiment: POSITIVE (Confidence: 0.9987)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "file_path = \"data/car_reviews.csv\"\n",
    "df = pd.read_csv(file_path, delimiter=\";\")\n",
    "\n",
    "reviews = df['Review'].tolist()\n",
    "real_labels = df['Class'].tolist()\n",
    "\n",
    "classifier = pipeline('sentiment-analysis', model='distilbert-base-uncased-finetuned-sst-2-english')\n",
    "\n",
    "predicted_labels = classifier(reviews)\n",
    "for review, prediction, label in zip(reviews, predicted_labels, real_labels):\n",
    "    print(f\"Review: {review}\\nActual Sentiment: {label}\\nPredicted Sentiment: {prediction['label']} (Confidence: {prediction['score']:.4f})\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ad084955-fa36-4079-9f86-528e733b58d9",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 195,
    "lastExecutedAt": 1739977372280,
    "lastExecutedByKernel": "15406b38-91f6-4175-ab8a-c77435acaf89",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "f1 = evaluate.load(\"f1\")\naccuracy = evaluate.load(\"accuracy\")\n\nreferences = [1 if label == \"POSITIVE\" else 0 for label in real_labels]\npredictions = [1 if label['label'] == \"POSITIVE\" else 0 for label in predicted_labels]\n\naccuracy_result_dict = accuracy.compute(references=references, predictions=predictions)\naccuracy_result = accuracy_result_dict['accuracy']\nf1_result_dict = f1.compute(references=references, predictions=predictions)\nf1_result = f1_result_dict['f1']\nprint(f\"Accuracy: {accuracy_result}\")\nprint(f\"F1 result: {f1_result}\")",
    "outputsMetadata": {
     "0": {
      "height": 59,
      "type": "stream"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8\n",
      "F1 result: 0.8571428571428571\n"
     ]
    }
   ],
   "source": [
    "f1 = evaluate.load(\"f1\")\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "\n",
    "references = [1 if label == \"POSITIVE\" else 0 for label in real_labels]\n",
    "predictions = [1 if label['label'] == \"POSITIVE\" else 0 for label in predicted_labels]\n",
    "\n",
    "accuracy_result_dict = accuracy.compute(references=references, predictions=predictions)\n",
    "accuracy_result = accuracy_result_dict['accuracy']\n",
    "f1_result_dict = f1.compute(references=references, predictions=predictions)\n",
    "f1_result = f1_result_dict['f1']\n",
    "print(f\"Accuracy: {accuracy_result}\")\n",
    "print(f\"F1 result: {f1_result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc815262-717f-4c65-9de9-186e5844a005",
   "metadata": {},
   "source": [
    "## TASK 2 - Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d070805b-ccac-477f-a45b-fc43b6112514",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 3219,
    "lastExecutedAt": 1739977375499,
    "lastExecutedByKernel": "15406b38-91f6-4175-ab8a-c77435acaf89",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "first_review = reviews[0]\ntranslator = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-en-es\")\n\ntranslated_review = translator(first_review, max_length=27)[0]['translation_text']\nprint(f\"Model translation:\\n{translated_review}\")\n\nwith open(\"data/reference_translations.txt\", 'r') as file:\n    lines = file.readlines()\nreferences = [line.strip() for line in lines]\nprint(f\"Spanish translation references:\\n{references}\")",
    "outputsMetadata": {
     "0": {
      "height": 59,
      "type": "stream"
     },
     "1": {
      "height": 164,
      "type": "stream"
     },
     "7": {
      "height": 59,
      "type": "stream"
     },
     "8": {
      "height": 164,
      "type": "stream"
     }
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your input_length: 365 is bigger than 0.9 * max_length: 27. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model translation:\n",
      "Estoy muy satisfecho con mi 2014 Nissan NV SL. Uso esta furgoneta para mis entregas de negocios y uso personal.\n",
      "Spanish translation references:\n",
      "['Estoy muy satisfecho con mi Nissan NV SL 2014. Utilizo esta camioneta para mis entregas comerciales y uso personal.', 'Estoy muy satisfecho con mi Nissan NV SL 2014. Uso esta furgoneta para mis entregas comerciales y uso personal.']\n"
     ]
    }
   ],
   "source": [
    "first_review = reviews[0]\n",
    "translator = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-en-es\")\n",
    "\n",
    "translated_review = translator(first_review, max_length=27)[0]['translation_text']\n",
    "print(f\"Model translation:\\n{translated_review}\")\n",
    "\n",
    "with open(\"data/reference_translations.txt\", 'r') as file:\n",
    "    lines = file.readlines()\n",
    "references = [line.strip() for line in lines]\n",
    "print(f\"Spanish translation references:\\n{references}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ef6a49d1-1fa8-44b6-9457-14b1dcd5a99b",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": null,
    "lastExecutedAt": null,
    "lastExecutedByKernel": null,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": null,
    "outputsMetadata": {
     "0": {
      "height": 38,
      "type": "stream"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6022774485691839\n"
     ]
    }
   ],
   "source": [
    "bleu = evaluate.load(\"bleu\")\n",
    "bleu_score = bleu.compute(predictions=[translated_review], references=[references])\n",
    "print(bleu_score['bleu'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab15ea98-8025-4fbe-a359-f7129a762a8b",
   "metadata": {},
   "source": [
    "## TASK 3 - Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b37b174e-c18c-4fe4-b989-9806e03d9d3c",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": null,
    "lastExecutedAt": null,
    "lastExecutedByKernel": null,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": null,
    "outputsMetadata": {
     "5": {
      "height": 227,
      "type": "stream"
     }
    }
   },
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.007304191589355469,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading",
       "rate": null,
       "total": 107,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8de989e532d445ca8bfc87627ddd68c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/107 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0074007511138916016,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading",
       "rate": null,
       "total": 477,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fb104df511849e899827e57d9e8f065",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/477 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0071833133697509766,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading",
       "rate": null,
       "total": 231508,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38893ede02b1424c80bf170a0dfbf658",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.007334232330322266,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading",
       "rate": null,
       "total": 112,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7233b500766b4f26874edfd4908c2384",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0071942806243896484,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading",
       "rate": null,
       "total": 133490920,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab520ef880084326bb5446364d713c89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/133M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context:\n",
      "The car is fine. It's a bit loud and not very powerful. On one hand, compared to its peers, the interior is well-built. The transmission failed a few years ago, and the dealer replaced it under warranty with no issues. Now, about 60k miles later, the transmission is failing again. It sounds like a truck, and the issues are well-documented. The dealer tells me it is normal, refusing to do anything to resolve the issue. After owning the car for 4 years, there are many other vehicles I would purchase over this one. Initially, I really liked what the brand is about: ride quality, reliability, etc. But I will not purchase another one. Despite these concerns, I must say, the level of comfort in the car has always been satisfactory, but not worth the rest of issues found.\n",
      "Answer:  ride quality, reliability\n"
     ]
    }
   ],
   "source": [
    "model_ckp = \"deepset/minilm-uncased-squad2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckp)\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(model_ckp)\n",
    "\n",
    "context = reviews[1]\n",
    "print(f\"Context:\\n{context}\")\n",
    "question = \"What did he like about the brand?\"\n",
    "inputs = tokenizer(question, context, return_tensors=\"pt\")\n",
    "                   \n",
    "with torch.no_grad():\n",
    "  outputs = model(**inputs)\n",
    "start_idx = torch.argmax(outputs.start_logits)\n",
    "end_idx = torch.argmax(outputs.end_logits) + 1\n",
    "answer_span = inputs[\"input_ids\"][0][start_idx:end_idx]\n",
    "\n",
    "answer = tokenizer.decode(answer_span)\n",
    "print(\"Answer: \", answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe9d946-43e1-416d-a165-6047faeae504",
   "metadata": {},
   "source": [
    "## TASK 4 - Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0d79aa2d-6efa-41df-b68a-f9d88faa6733",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": null,
    "lastExecutedAt": null,
    "lastExecutedByKernel": null,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": null,
    "outputsMetadata": {
     "0": {
      "height": 269,
      "type": "stream"
     },
     "7": {
      "height": 101,
      "type": "stream"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text:\n",
      "I've been dreaming of owning an SUV for quite a while, but I've been driving cars that were already paid for during an extended period. I ultimately made the decision to transition to a brand-new car, which, of course, involved taking on new payments. However, given that I don't drive extensively, I was inclined to avoid a substantial financial commitment. The Nissan Rogue provides me with the desired SUV experience without burdening me with an exorbitant payment; the financial arrangement is quite reasonable. Handling and styling are great; I have hauled 12 bags of mulch in the back with the seats down and could have held more. I am VERY satisfied overall. I find myself needing to exercise extra caution when making lane changes, particularly owing to the blind spots resulting from the small side windows situated towards the rear of the vehicle. To address this concern, I am actively engaged in making adjustments to my mirrors and consciously reducing the frequency of lane changes. The engine delivers strong performance, and the ride is really smooth.\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.006736040115356445,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading",
       "rate": null,
       "total": 1380,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b61aa9fc724e4c6c828b14b53927c9f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.38k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.007081031799316406,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading",
       "rate": null,
       "total": 242085627,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1f96c15868d41778f6510357465f44d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/242M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.006741046905517578,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading",
       "rate": null,
       "total": 1924,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e89afbca50f44f28d3dfbc75526fb95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.92k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.008579254150390625,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading",
       "rate": null,
       "total": 791656,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fd8c77a36c24afb8cdb7b469dc036fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.007286548614501953,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading",
       "rate": null,
       "total": 2422193,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4482f35a6f34538a35fe649fdee6684",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/2.42M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.006815433502197266,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading",
       "rate": null,
       "total": 1786,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13edddaa971f4be78009942fe2c94878",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.79k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarized text:\n",
      "the Nissan Rogue provides me with the desired SUV experience without burdening me with an exorbitant payment; the financial arrangement is quite reasonable. I have hauled 12 bags of mulch in the back with the seats down and could have held more.\n"
     ]
    }
   ],
   "source": [
    "text_to_summarize = reviews[-1]\n",
    "print(f\"Original text:\\n{text_to_summarize}\")\n",
    "\n",
    "model_name = \"cnicu/t5-small-booksum\"\n",
    "summarizer = pipeline(\"summarization\", model=model_name)\n",
    "outputs = summarizer(text_to_summarize, max_length=53)\n",
    "summarized_text = outputs[0]['summary_text']\n",
    "print(f\"Summarized text:\\n{summarized_text}\")"
   ]
  }
 ],
 "metadata": {
  "editor": "DataLab",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
