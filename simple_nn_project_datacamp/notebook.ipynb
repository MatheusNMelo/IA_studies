{"cells":[{"source":"# Practical Exam: Customer Purchase Prediction\n\nRetailTech Solutions is a fast-growing international e-commerce platform operating in over 20 countries across Europe, North America, and Asia. They specialize in fashion, electronics, and home goods, with a unique business model that combines traditional retail with a marketplace for independent sellers.\n\nThe company has seen rapid growth. A key part of their success has been their data-driven approach to personalization. However, as they plan their expansion into new markets, they need to improve their ability to predict customer behavior.\n\nTheir marketing team wants to predict which customers are most likely to make a purchase based on their browsing behavior.\n\nAs an AI Engineer, you will help build this prediction system. Your work will directly impact RetailTech's growth strategy and their goal of increasing revenue.\n\n\n## Data Description\n\n| Column Name | Criteria |\n|------------|----------|\n| customer_id | Integer. Unique identifier for each customer. No missing values. |\n| time_spent | Float. Minutes spent on website per session. Missing values should be replaced with median. |\n| pages_viewed | Integer. Number of pages viewed in session. Missing values should be replaced with mean. |\n| basket_value | Float. Value of items in basket. Missing values should be replaced with 0. |\n| device_type | String. One of: Mobile, Desktop, Tablet. Missing values should be replaced with \"Unknown\". |\n| customer_type | String. One of: New, Returning. Missing values should be replaced with \"New\". |\n| purchase | Binary. Whether customer made a purchase (1) or not (0). Target variable. |","metadata":{},"id":"8d0bcede-0826-475c-8678-72835c042b37","cell_type":"markdown"},{"source":"# Task 1\n\nThe marketing team has collected customer session data in `raw_customer_data.csv`, but it contains missing values and inconsistencies that need to be addressed.\nCreate a cleaned version of the dataframe:\n\n- Start with the data in the file `raw_customer_data.csv`\n- Your output should be a DataFrame named `clean_data`\n- All column names and values should match the table below.\n</br>\n\n| Column Name | Criteria |\n|------------|----------|\n| customer_id | Integer. Unique identifier for each customer. No missing values. |\n| time_spent | Float. Minutes spent on website per session. Missing values should be replaced with median. |\n| pages_viewed | Integer. Number of pages viewed in session. Missing values should be replaced with mean. |\n| basket_value | Float. Value of items in basket. Missing values should be replaced with 0. |\n| device_type | String. One of: Mobile, Desktop, Tablet. Missing values should be replaced with \"Unknown\". |\n| customer_type | String. One of: New, Returning. Missing values should be replaced with \"New\". |\n| purchase | Binary. Whether customer made a purchase (1) or not (0). Target variable. |","metadata":{},"id":"c0d5a3bb-bbae-4d39-a6c6-daa46c470347","cell_type":"markdown"},{"source":"# Write your answer to Task 1 here \nimport pandas as pd\ndata = pd.read_csv(\"raw_customer_data.csv\")\ndata[\"device_type\"].fillna(\"Unknown\",inplace=True)\ndata[\"customer_type\"].fillna(\"New\",inplace=True)\ndata[\"basket_value\"].fillna(float(0),inplace=True)\nviews_mean = data['pages_viewed'].mean()\ndata['pages_viewed'].fillna(views_mean, inplace=True)\ntime_median = data['time_spent'].median()\ndata['time_spent'].fillna(time_median, inplace=True)\nclean_data = data.copy()\nclean_data[\"pages_viewed\"] = clean_data[\"pages_viewed\"].astype(int)\nclean_data[\"device_type\"] = clean_data[\"device_type\"].astype(str)\nclean_data[\"customer_type\"] = clean_data[\"customer_type\"].astype(str)\nclean_data[\"purchase\"] = clean_data[\"purchase\"].astype(bool)\nclean_data.info()","metadata":{"executionCancelledAt":null,"executionTime":52,"lastExecutedAt":1741024706928,"lastExecutedByKernel":"43f2a363-e729-4f6c-b7e7-8eab407b85d2","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Write your answer to Task 1 here \nimport pandas as pd\ndata = pd.read_csv(\"raw_customer_data.csv\")\ndata[\"device_type\"].fillna(\"Unknown\",inplace=True)\ndata[\"customer_type\"].fillna(\"New\",inplace=True)\ndata[\"basket_value\"].fillna(float(0),inplace=True)\nviews_mean = data['pages_viewed'].mean()\ndata['pages_viewed'].fillna(views_mean, inplace=True)\ntime_median = data['time_spent'].median()\ndata['time_spent'].fillna(time_median, inplace=True)\nclean_data = data.copy()\nclean_data[\"pages_viewed\"] = clean_data[\"pages_viewed\"].astype(int)\nclean_data[\"device_type\"] = clean_data[\"device_type\"].astype(str)\nclean_data[\"customer_type\"] = clean_data[\"customer_type\"].astype(str)\nclean_data[\"purchase\"] = clean_data[\"purchase\"].astype(bool)\nclean_data.info()","outputsMetadata":{"0":{"height":311,"type":"stream"}}},"id":"5ce18b54-29af-4beb-bc8c-79c4e21bcd52","cell_type":"code","execution_count":88,"outputs":[{"output_type":"stream","name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 500 entries, 0 to 499\nData columns (total 7 columns):\n #   Column         Non-Null Count  Dtype  \n---  ------         --------------  -----  \n 0   customer_id    500 non-null    int64  \n 1   time_spent     500 non-null    float64\n 2   pages_viewed   500 non-null    int64  \n 3   basket_value   500 non-null    float64\n 4   device_type    500 non-null    object \n 5   customer_type  500 non-null    object \n 6   purchase       500 non-null    bool   \ndtypes: bool(1), float64(2), int64(2), object(2)\nmemory usage: 24.1+ KB\n"}]},{"source":"# Task 2\nThe pre-cleaned dataset `model_data.csv` needs to be prepared for our neural network.\nCreate the model features:\n\n- Start with the data in the file `model_data.csv`\n- Scale numerical features (`time_spent`, `pages_viewed`, `basket_value`) to 0-1 range\n- Apply one-hot encoding to the categorical features (`device_type`, `customer_type`)\n    - The column names should have the following format: variable_name_category_name (e.g., `device_type_Desktop`)\n- Your output should be a DataFrame named `model_feature_set`, with all column names from `model_data.csv` except for the columns where one-hot encoding was applied.\n","metadata":{},"id":"026b3c30-d3b0-4762-ae10-0f2880873bdc","cell_type":"markdown"},{"source":"# Write your answer to Task 2 here\nfrom sklearn.preprocessing import MinMaxScaler, OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\n\nmodel_data = pd.read_csv(\"model_data.csv\")\n\nnmr_features = ['time_spent', 'pages_viewed', 'basket_value']\nctg_features = ['device_type', 'customer_type']\nother = ['customer_id','purchase']\n\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', MinMaxScaler(), nmr_features),  # Scale numeric features\n        ('cat', OneHotEncoder(), ctg_features)  # Encode categorical features\n    ]\n)\n\nprocessed_data = preprocessor.fit_transform(model_data)\n\nmodel_feature_set = pd.DataFrame(processed_data, columns= nmr_features + list(preprocessor.named_transformers_['cat'].get_feature_names_out(ctg_features)))\nmodel_feature_set[other] = model_data[other]","metadata":{"executionCancelledAt":null,"executionTime":52,"lastExecutedAt":1741024706980,"lastExecutedByKernel":"43f2a363-e729-4f6c-b7e7-8eab407b85d2","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Write your answer to Task 2 here\nfrom sklearn.preprocessing import MinMaxScaler, OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\n\nmodel_data = pd.read_csv(\"model_data.csv\")\n\nnmr_features = ['time_spent', 'pages_viewed', 'basket_value']\nctg_features = ['device_type', 'customer_type']\nother = ['customer_id','purchase']\n\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', MinMaxScaler(), nmr_features),  # Scale numeric features\n        ('cat', OneHotEncoder(), ctg_features)  # Encode categorical features\n    ]\n)\n\nprocessed_data = preprocessor.fit_transform(model_data)\n\nmodel_feature_set = pd.DataFrame(processed_data, columns= nmr_features + list(preprocessor.named_transformers_['cat'].get_feature_names_out(ctg_features)))\nmodel_feature_set[other] = model_data[other]","outputsMetadata":{"0":{"height":260,"type":"dataFrame","tableState":{"quickFilterText":""}}}},"id":"6d47e440-c4ab-45cf-af40-53181764bac4","cell_type":"code","execution_count":89,"outputs":[]},{"source":"# Task 3\n\nNow that all preparatory work has been done, create and train a neural network that would allow the company to predict purchases.\n\n- Using PyTorch, create a network with:\n   - At least one hidden layer with 8 units\n   - ReLU activation for hidden layer\n   - Sigmoid activation for the output layer\n- Using the prepared features in `input_model_features.csv`, train the model to predict purchases. \n- Use the validation dataset `validation_features.csv` to predict new values based on the trained model. \n- Your model should be named `purchase_model` and your output should be a DataFrame named `validation_predictions` with columns `customer_id` and `purchase`. The `purchase` column must be your predicted values.\n","metadata":{},"id":"10a02327-d528-441c-87bf-098f9d6415e1","cell_type":"markdown"},{"source":"import torch.nn as nn\nimport torch\ntrain = pd.read_csv(\"input_model_features.csv\")\ntest = pd.read_csv(\"validation_features.csv\")\n\nfeats = ['time_spent', 'pages_viewed', 'basket_value','device_type_Desktop', 'device_type_Mobile', 'device_type_Tablet','device_type_Unknown', 'customer_type_New', 'customer_type_Returning']\ntarget = 'purchase'\n\nfeats_train = torch.tensor(train[feats].values, dtype=torch.float32)\ntarget_train =  torch.tensor(train[target].values, dtype=torch.float32)\nfeats_test =  torch.tensor(test[feats].values, dtype=torch.float32)\n\npurchase_model = nn.Sequential(\n    nn.Linear(9,8),\n    nn.ReLU(),\n    nn.Linear(8,1),\n    nn.Sigmoid()\n)\n\ncriterion = nn.BCELoss()\noptimizer = torch.optim.Adam(purchase_model.parameters(), lr=0.01)\n\nnum_epochs = 100\nfor epoch in range(num_epochs):\n    outputs = purchase_model(feats_train).squeeze()\n    loss = criterion(outputs, target_train)\n\n    optimizer.zero_grad()\n    loss.backward()\n    optimizer.step()\n    if (epoch + 1) % 10 == 0:\n        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\nwith torch.no_grad():\n    purchase_model.eval()\n    outputs = purchase_model(feats_test).squeeze()\n    predicted = (outputs >= 0.5).float()\n    \nvalidation_predictions = pd.DataFrame()\nvalidation_predictions['customer_id'] = test['customer_id']\nvalidation_predictions['purchase'] = predicted.numpy()\nvalidation_predictions.head(20)","metadata":{"executionCancelledAt":null,"executionTime":267,"lastExecutedAt":1741024707247,"lastExecutedByKernel":"43f2a363-e729-4f6c-b7e7-8eab407b85d2","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"import torch.nn as nn\nimport torch\ntrain = pd.read_csv(\"input_model_features.csv\")\ntest = pd.read_csv(\"validation_features.csv\")\n\nfeats = ['time_spent', 'pages_viewed', 'basket_value','device_type_Desktop', 'device_type_Mobile', 'device_type_Tablet','device_type_Unknown', 'customer_type_New', 'customer_type_Returning']\ntarget = 'purchase'\n\nfeats_train = torch.tensor(train[feats].values, dtype=torch.float32)\ntarget_train =  torch.tensor(train[target].values, dtype=torch.float32)\nfeats_test =  torch.tensor(test[feats].values, dtype=torch.float32)\n\npurchase_model = nn.Sequential(\n    nn.Linear(9,8),\n    nn.ReLU(),\n    nn.Linear(8,1),\n    nn.Sigmoid()\n)\n\ncriterion = nn.BCELoss()\noptimizer = torch.optim.Adam(purchase_model.parameters(), lr=0.01)\n\nnum_epochs = 100\nfor epoch in range(num_epochs):\n    outputs = purchase_model(feats_train).squeeze()\n    loss = criterion(outputs, target_train)\n\n    optimizer.zero_grad()\n    loss.backward()\n    optimizer.step()\n    if (epoch + 1) % 10 == 0:\n        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\nwith torch.no_grad():\n    purchase_model.eval()\n    outputs = purchase_model(feats_test).squeeze()\n    predicted = (outputs >= 0.5).float()\n    \nvalidation_predictions = pd.DataFrame()\nvalidation_predictions['customer_id'] = test['customer_id']\nvalidation_predictions['purchase'] = predicted.numpy()\nvalidation_predictions.head(20)","outputsMetadata":{"0":{"height":143,"type":"stream"},"1":{"height":500,"type":"dataFrame","tableState":{"quickFilterText":""}}}},"id":"efcbda28-3c89-480d-b77a-c7f27ac759d5","cell_type":"code","execution_count":90,"outputs":[{"output_type":"stream","name":"stdout","text":"Epoch [10/100], Loss: 0.5297\nEpoch [20/100], Loss: 0.5078\nEpoch [30/100], Loss: 0.5051\nEpoch [40/100], Loss: 0.4989\nEpoch [50/100], Loss: 0.4953\nEpoch [60/100], Loss: 0.4917\nEpoch [70/100], Loss: 0.4882\nEpoch [80/100], Loss: 0.4844\nEpoch [90/100], Loss: 0.4807\nEpoch [100/100], Loss: 0.4776\n"},{"output_type":"execute_result","data":{"application/com.datacamp.data-table.v2+json":{"table":{"schema":{"fields":[{"name":"index","type":"integer"},{"name":"customer_id","type":"integer"},{"name":"purchase","type":"number"}],"primaryKey":["index"],"pandas_version":"1.4.0"},"data":{"index":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19],"customer_id":[1801,1802,1803,1804,1805,1806,1807,1808,1809,1810,1811,1812,1813,1814,1815,1816,1817,1818,1819,1820],"purchase":[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1]}},"total_rows":20,"truncation_type":null},"text/plain":"    customer_id  purchase\n0          1801       1.0\n1          1802       1.0\n2          1803       1.0\n3          1804       1.0\n4          1805       1.0\n5          1806       1.0\n6          1807       1.0\n7          1808       1.0\n8          1809       1.0\n9          1810       1.0\n10         1811       1.0\n11         1812       1.0\n12         1813       1.0\n13         1814       1.0\n14         1815       1.0\n15         1816       1.0\n16         1817       1.0\n17         1818       1.0\n18         1819       1.0\n19         1820       1.0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>customer_id</th>\n      <th>purchase</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1801</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1802</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1803</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1804</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1805</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>1806</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>1807</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>1808</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>1809</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>1810</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>1811</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>1812</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>1813</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>1814</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>1815</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>1816</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>1817</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>1818</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>1819</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>1820</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{"application/com.datacamp.data-table.v2+json":{"status":"success"}},"execution_count":90}]}],"metadata":{"colab":{"name":"Welcome to DataCamp Workspaces.ipynb","provenance":[]},"editor":"DataLab","kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.8.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":5}