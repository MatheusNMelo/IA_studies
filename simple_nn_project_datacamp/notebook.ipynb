{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d0bcede-0826-475c-8678-72835c042b37",
   "metadata": {},
   "source": [
    "# Practical Exam: Customer Purchase Prediction\n",
    "\n",
    "RetailTech Solutions is a fast-growing international e-commerce platform operating in over 20 countries across Europe, North America, and Asia. They specialize in fashion, electronics, and home goods, with a unique business model that combines traditional retail with a marketplace for independent sellers.\n",
    "\n",
    "The company has seen rapid growth. A key part of their success has been their data-driven approach to personalization. However, as they plan their expansion into new markets, they need to improve their ability to predict customer behavior.\n",
    "\n",
    "Their marketing team wants to predict which customers are most likely to make a purchase based on their browsing behavior.\n",
    "\n",
    "As an AI Engineer, you will help build this prediction system. Your work will directly impact RetailTech's growth strategy and their goal of increasing revenue.\n",
    "\n",
    "\n",
    "## Data Description\n",
    "\n",
    "| Column Name | Criteria |\n",
    "|------------|----------|\n",
    "| customer_id | Integer. Unique identifier for each customer. No missing values. |\n",
    "| time_spent | Float. Minutes spent on website per session. Missing values should be replaced with median. |\n",
    "| pages_viewed | Integer. Number of pages viewed in session. Missing values should be replaced with mean. |\n",
    "| basket_value | Float. Value of items in basket. Missing values should be replaced with 0. |\n",
    "| device_type | String. One of: Mobile, Desktop, Tablet. Missing values should be replaced with \"Unknown\". |\n",
    "| customer_type | String. One of: New, Returning. Missing values should be replaced with \"New\". |\n",
    "| purchase | Binary. Whether customer made a purchase (1) or not (0). Target variable. |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d5a3bb-bbae-4d39-a6c6-daa46c470347",
   "metadata": {},
   "source": [
    "# Task 1\n",
    "\n",
    "The marketing team has collected customer session data in `raw_customer_data.csv`, but it contains missing values and inconsistencies that need to be addressed.\n",
    "Create a cleaned version of the dataframe:\n",
    "\n",
    "- Start with the data in the file `raw_customer_data.csv`\n",
    "- Your output should be a DataFrame named `clean_data`\n",
    "- All column names and values should match the table below.\n",
    "</br>\n",
    "\n",
    "| Column Name | Criteria |\n",
    "|------------|----------|\n",
    "| customer_id | Integer. Unique identifier for each customer. No missing values. |\n",
    "| time_spent | Float. Minutes spent on website per session. Missing values should be replaced with median. |\n",
    "| pages_viewed | Integer. Number of pages viewed in session. Missing values should be replaced with mean. |\n",
    "| basket_value | Float. Value of items in basket. Missing values should be replaced with 0. |\n",
    "| device_type | String. One of: Mobile, Desktop, Tablet. Missing values should be replaced with \"Unknown\". |\n",
    "| customer_type | String. One of: New, Returning. Missing values should be replaced with \"New\". |\n",
    "| purchase | Binary. Whether customer made a purchase (1) or not (0). Target variable. |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "5ce18b54-29af-4beb-bc8c-79c4e21bcd52",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 52,
    "lastExecutedAt": 1741024706928,
    "lastExecutedByKernel": "43f2a363-e729-4f6c-b7e7-8eab407b85d2",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# Write your answer to Task 1 here \nimport pandas as pd\ndata = pd.read_csv(\"raw_customer_data.csv\")\ndata[\"device_type\"].fillna(\"Unknown\",inplace=True)\ndata[\"customer_type\"].fillna(\"New\",inplace=True)\ndata[\"basket_value\"].fillna(float(0),inplace=True)\nviews_mean = data['pages_viewed'].mean()\ndata['pages_viewed'].fillna(views_mean, inplace=True)\ntime_median = data['time_spent'].median()\ndata['time_spent'].fillna(time_median, inplace=True)\nclean_data = data.copy()\nclean_data[\"pages_viewed\"] = clean_data[\"pages_viewed\"].astype(int)\nclean_data[\"device_type\"] = clean_data[\"device_type\"].astype(str)\nclean_data[\"customer_type\"] = clean_data[\"customer_type\"].astype(str)\nclean_data[\"purchase\"] = clean_data[\"purchase\"].astype(bool)\nclean_data.info()",
    "outputsMetadata": {
     "0": {
      "height": 311,
      "type": "stream"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 500 entries, 0 to 499\n",
      "Data columns (total 7 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   customer_id    500 non-null    int64  \n",
      " 1   time_spent     500 non-null    float64\n",
      " 2   pages_viewed   500 non-null    int64  \n",
      " 3   basket_value   500 non-null    float64\n",
      " 4   device_type    500 non-null    object \n",
      " 5   customer_type  500 non-null    object \n",
      " 6   purchase       500 non-null    bool   \n",
      "dtypes: bool(1), float64(2), int64(2), object(2)\n",
      "memory usage: 24.1+ KB\n"
     ]
    }
   ],
   "source": [
    "# Write your answer to Task 1 here \n",
    "import pandas as pd\n",
    "data = pd.read_csv(\"raw_customer_data.csv\")\n",
    "data[\"device_type\"].fillna(\"Unknown\",inplace=True)\n",
    "data[\"customer_type\"].fillna(\"New\",inplace=True)\n",
    "data[\"basket_value\"].fillna(float(0),inplace=True)\n",
    "views_mean = data['pages_viewed'].mean()\n",
    "data['pages_viewed'].fillna(views_mean, inplace=True)\n",
    "time_median = data['time_spent'].median()\n",
    "data['time_spent'].fillna(time_median, inplace=True)\n",
    "clean_data = data.copy()\n",
    "clean_data[\"pages_viewed\"] = clean_data[\"pages_viewed\"].astype(int)\n",
    "clean_data[\"device_type\"] = clean_data[\"device_type\"].astype(str)\n",
    "clean_data[\"customer_type\"] = clean_data[\"customer_type\"].astype(str)\n",
    "clean_data[\"purchase\"] = clean_data[\"purchase\"].astype(bool)\n",
    "clean_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026b3c30-d3b0-4762-ae10-0f2880873bdc",
   "metadata": {},
   "source": [
    "# Task 2\n",
    "The pre-cleaned dataset `model_data.csv` needs to be prepared for our neural network.\n",
    "Create the model features:\n",
    "\n",
    "- Start with the data in the file `model_data.csv`\n",
    "- Scale numerical features (`time_spent`, `pages_viewed`, `basket_value`) to 0-1 range\n",
    "- Apply one-hot encoding to the categorical features (`device_type`, `customer_type`)\n",
    "    - The column names should have the following format: variable_name_category_name (e.g., `device_type_Desktop`)\n",
    "- Your output should be a DataFrame named `model_feature_set`, with all column names from `model_data.csv` except for the columns where one-hot encoding was applied.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d47e440-c4ab-45cf-af40-53181764bac4",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 52,
    "lastExecutedAt": 1741024706980,
    "lastExecutedByKernel": "43f2a363-e729-4f6c-b7e7-8eab407b85d2",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# Write your answer to Task 2 here\nfrom sklearn.preprocessing import MinMaxScaler, OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\n\nmodel_data = pd.read_csv(\"model_data.csv\")\n\nnmr_features = ['time_spent', 'pages_viewed', 'basket_value']\nctg_features = ['device_type', 'customer_type']\nother = ['customer_id','purchase']\n\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', MinMaxScaler(), nmr_features),  # Scale numeric features\n        ('cat', OneHotEncoder(), ctg_features)  # Encode categorical features\n    ]\n)\n\nprocessed_data = preprocessor.fit_transform(model_data)\n\nmodel_feature_set = pd.DataFrame(processed_data, columns= nmr_features + list(preprocessor.named_transformers_['cat'].get_feature_names_out(ctg_features)))\nmodel_feature_set[other] = model_data[other]",
    "outputsMetadata": {
     "0": {
      "height": 260,
      "tableState": {
       "quickFilterText": ""
      },
      "type": "dataFrame"
     }
    }
   },
   "outputs": [],
   "source": [
    "# Write your answer to Task 2 here\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "model_data = pd.read_csv(\"model_data.csv\")\n",
    "\n",
    "nmr_features = ['time_spent', 'pages_viewed', 'basket_value']\n",
    "ctg_features = ['device_type', 'customer_type']\n",
    "other = ['customer_id','purchase']\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', MinMaxScaler(), nmr_features),\n",
    "        ('cat', OneHotEncoder(), ctg_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "processed_data = preprocessor.fit_transform(model_data)\n",
    "\n",
    "model_feature_set = pd.DataFrame(processed_data, columns= nmr_features + list(preprocessor.named_transformers_['cat'].get_feature_names_out(ctg_features)))\n",
    "model_feature_set[other] = model_data[other]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a02327-d528-441c-87bf-098f9d6415e1",
   "metadata": {},
   "source": [
    "# Task 3\n",
    "\n",
    "Now that all preparatory work has been done, create and train a neural network that would allow the company to predict purchases.\n",
    "\n",
    "- Using PyTorch, create a network with:\n",
    "   - At least one hidden layer with 8 units\n",
    "   - ReLU activation for hidden layer\n",
    "   - Sigmoid activation for the output layer\n",
    "- Using the prepared features in `input_model_features.csv`, train the model to predict purchases. \n",
    "- Use the validation dataset `validation_features.csv` to predict new values based on the trained model. \n",
    "- Your model should be named `purchase_model` and your output should be a DataFrame named `validation_predictions` with columns `customer_id` and `purchase`. The `purchase` column must be your predicted values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "efcbda28-3c89-480d-b77a-c7f27ac759d5",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 267,
    "lastExecutedAt": 1741024707247,
    "lastExecutedByKernel": "43f2a363-e729-4f6c-b7e7-8eab407b85d2",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "import torch.nn as nn\nimport torch\ntrain = pd.read_csv(\"input_model_features.csv\")\ntest = pd.read_csv(\"validation_features.csv\")\n\nfeats = ['time_spent', 'pages_viewed', 'basket_value','device_type_Desktop', 'device_type_Mobile', 'device_type_Tablet','device_type_Unknown', 'customer_type_New', 'customer_type_Returning']\ntarget = 'purchase'\n\nfeats_train = torch.tensor(train[feats].values, dtype=torch.float32)\ntarget_train =  torch.tensor(train[target].values, dtype=torch.float32)\nfeats_test =  torch.tensor(test[feats].values, dtype=torch.float32)\n\npurchase_model = nn.Sequential(\n    nn.Linear(9,8),\n    nn.ReLU(),\n    nn.Linear(8,1),\n    nn.Sigmoid()\n)\n\ncriterion = nn.BCELoss()\noptimizer = torch.optim.Adam(purchase_model.parameters(), lr=0.01)\n\nnum_epochs = 100\nfor epoch in range(num_epochs):\n    outputs = purchase_model(feats_train).squeeze()\n    loss = criterion(outputs, target_train)\n\n    optimizer.zero_grad()\n    loss.backward()\n    optimizer.step()\n    if (epoch + 1) % 10 == 0:\n        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\nwith torch.no_grad():\n    purchase_model.eval()\n    outputs = purchase_model(feats_test).squeeze()\n    predicted = (outputs >= 0.5).float()\n    \nvalidation_predictions = pd.DataFrame()\nvalidation_predictions['customer_id'] = test['customer_id']\nvalidation_predictions['purchase'] = predicted.numpy()\nvalidation_predictions.head(20)",
    "outputsMetadata": {
     "0": {
      "height": 143,
      "type": "stream"
     },
     "1": {
      "height": 500,
      "tableState": {
       "quickFilterText": ""
      },
      "type": "dataFrame"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Loss: 0.5297\n",
      "Epoch [20/100], Loss: 0.5078\n",
      "Epoch [30/100], Loss: 0.5051\n",
      "Epoch [40/100], Loss: 0.4989\n",
      "Epoch [50/100], Loss: 0.4953\n",
      "Epoch [60/100], Loss: 0.4917\n",
      "Epoch [70/100], Loss: 0.4882\n",
      "Epoch [80/100], Loss: 0.4844\n",
      "Epoch [90/100], Loss: 0.4807\n",
      "Epoch [100/100], Loss: 0.4776\n"
     ]
    },
    {
     "data": {
      "application/com.datacamp.data-table.v2+json": {
       "table": {
        "data": {
         "customer_id": [
          1801,
          1802,
          1803,
          1804,
          1805,
          1806,
          1807,
          1808,
          1809,
          1810,
          1811,
          1812,
          1813,
          1814,
          1815,
          1816,
          1817,
          1818,
          1819,
          1820
         ],
         "index": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19
         ],
         "purchase": [
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1
         ]
        },
        "schema": {
         "fields": [
          {
           "name": "index",
           "type": "integer"
          },
          {
           "name": "customer_id",
           "type": "integer"
          },
          {
           "name": "purchase",
           "type": "number"
          }
         ],
         "pandas_version": "1.4.0",
         "primaryKey": [
          "index"
         ]
        }
       },
       "total_rows": 20,
       "truncation_type": null
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>purchase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1801</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1802</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1803</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1804</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1805</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1806</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1807</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1808</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1809</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1810</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1811</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1812</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1813</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1814</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1815</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1816</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1817</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1818</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1819</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1820</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    customer_id  purchase\n",
       "0          1801       1.0\n",
       "1          1802       1.0\n",
       "2          1803       1.0\n",
       "3          1804       1.0\n",
       "4          1805       1.0\n",
       "5          1806       1.0\n",
       "6          1807       1.0\n",
       "7          1808       1.0\n",
       "8          1809       1.0\n",
       "9          1810       1.0\n",
       "10         1811       1.0\n",
       "11         1812       1.0\n",
       "12         1813       1.0\n",
       "13         1814       1.0\n",
       "14         1815       1.0\n",
       "15         1816       1.0\n",
       "16         1817       1.0\n",
       "17         1818       1.0\n",
       "18         1819       1.0\n",
       "19         1820       1.0"
      ]
     },
     "execution_count": 90,
     "metadata": {
      "application/com.datacamp.data-table.v2+json": {
       "status": "success"
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "train = pd.read_csv(\"input_model_features.csv\")\n",
    "test = pd.read_csv(\"validation_features.csv\")\n",
    "\n",
    "feats = ['time_spent', 'pages_viewed', 'basket_value','device_type_Desktop', 'device_type_Mobile', 'device_type_Tablet','device_type_Unknown', 'customer_type_New', 'customer_type_Returning']\n",
    "target = 'purchase'\n",
    "\n",
    "feats_train = torch.tensor(train[feats].values, dtype=torch.float32)\n",
    "target_train =  torch.tensor(train[target].values, dtype=torch.float32)\n",
    "feats_test =  torch.tensor(test[feats].values, dtype=torch.float32)\n",
    "\n",
    "purchase_model = nn.Sequential(\n",
    "    nn.Linear(9,8),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(8,1),\n",
    "    nn.Sigmoid()\n",
    ")\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(purchase_model.parameters(), lr=0.01)\n",
    "\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    outputs = purchase_model(feats_train).squeeze()\n",
    "    loss = criterion(outputs, target_train)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "with torch.no_grad():\n",
    "    purchase_model.eval()\n",
    "    outputs = purchase_model(feats_test).squeeze()\n",
    "    predicted = (outputs >= 0.5).float()\n",
    "    \n",
    "validation_predictions = pd.DataFrame()\n",
    "validation_predictions['customer_id'] = test['customer_id']\n",
    "validation_predictions['purchase'] = predicted.numpy()\n",
    "validation_predictions.head(20)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Welcome to DataCamp Workspaces.ipynb",
   "provenance": []
  },
  "editor": "DataLab",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
